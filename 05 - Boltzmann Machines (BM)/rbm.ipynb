{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boltzmann Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"ml-1m/movies.dat\", sep=\"::\", header=None, engine=\"python\", encoding=\"latin-1\")\n",
    "users = pd.read_csv(\"ml-1m/users.dat\", sep=\"::\", header=None, engine=\"python\", encoding=\"latin-1\")\n",
    "# index::userid::moviesid::rating::timestamp\n",
    "ratings = pd.read_csv(\"ml-1m/ratings.dat\", sep=\"::\", header=None, engine=\"python\", encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv(\"ml-100k/u1.base\", delimiter='\\t')\n",
    "training_set = np.array(training_set, dtype=\"int\")\n",
    "\n",
    "test_set = pd.read_csv(\"ml-100k/u1.test\", delimiter='\\t')\n",
    "test_set = np.array(test_set, dtype=\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the number of users and movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_users = int(max(max(training_set[:, 0]), max(training_set[:, 0])))\n",
    "nb_movies = int(max(max(training_set[:, 1]), max(training_set[:, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the data into an array with users in lines and movies in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_user in range(1, nb_users+1):\n",
    "        id_movies = data[:, 1][data[:, 0] == id_user]\n",
    "        id_ratings = data[:, 2][data[:, 0] == id_user]\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies-1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    \n",
    "    return new_data\n",
    "\n",
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the data into Torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the ratings into binary ratings 1 (Liked) or 0 (Disliked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set[training_set == 0] = -1\n",
    "training_set[training_set == 1] = 0\n",
    "training_set[training_set == 2] = 0\n",
    "training_set[training_set >= 3] = 1\n",
    "\n",
    "test_set[test_set == 0] = -1\n",
    "test_set[test_set == 1] = 0\n",
    "test_set[test_set == 2] = 0\n",
    "test_set[test_set >= 3] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the architecture of the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM:\n",
    "    def __init__(self, nv, nh):\n",
    "        self.W = torch.randn(nv, nh)  # Weights: (nv, nh)\n",
    "        self.a = torch.randn(1, nh)   # Hidden bias: (1, nh)\n",
    "        self.b = torch.randn(1, nv)   # Visible bias: (1, nv)\n",
    "\n",
    "    def sample_h(self, x):\n",
    "        wx = torch.mm(x, self.W)  # x: (batch_size, nv), W: (nv, nh)\n",
    "        activation = wx + self.a.expand_as(wx)\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "\n",
    "    def sample_v(self, y):\n",
    "        wy = torch.mm(y, self.W.t())  # y: (batch_size, nh), W.t(): (nh, nv)\n",
    "        activation = wy + self.b.expand_as(wy)\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "\n",
    "    def train(self, v0, vk, ph0, phk, lr=0.01):\n",
    "        self.W += lr * (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk))\n",
    "        self.b += lr * torch.sum((v0 - vk), 0)\n",
    "        self.a += lr * torch.sum((ph0 - phk), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv = len(training_set[0])\n",
    "# number of features\n",
    "nh = 100\n",
    "batch_size = 100\n",
    "rbm = RBM(nv, nh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 0.3850482702255249\n",
      "epoch: 2, loss: 0.3313833475112915\n",
      "epoch: 3, loss: 0.29904624819755554\n",
      "epoch: 4, loss: 0.2868254482746124\n",
      "epoch: 5, loss: 0.2776229977607727\n",
      "epoch: 6, loss: 0.27519598603248596\n",
      "epoch: 7, loss: 0.2738665044307709\n",
      "epoch: 8, loss: 0.266421914100647\n",
      "epoch: 9, loss: 0.2606787085533142\n",
      "epoch: 10, loss: 0.2625701129436493\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 10\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    train_loss = 0\n",
    "    s = 0.0\n",
    "    for id_user in range(0, nb_users - batch_size, batch_size):\n",
    "        # Get a batch of visible units\n",
    "        v0 = training_set[id_user:id_user + batch_size]  # Shape: (batch_size, n_visible)\n",
    "        vk = v0.clone()  # Initialize vk with v0\n",
    "\n",
    "        # Sample hidden units for v0\n",
    "        ph0, _ = rbm.sample_h(v0)  # ph0 shape: (batch_size, n_hidden)\n",
    "\n",
    "        # Perform CD-k (random walk)\n",
    "        for k in range(10):\n",
    "            _, hk = rbm.sample_h(vk)  # hk shape: (batch_size, n_hidden)\n",
    "            _, vk = rbm.sample_v(hk)  # vk shape: (batch_size, n_visible)\n",
    "            # Preserve missing ratings\n",
    "            vk[v0 < 0] = v0[v0 < 0]\n",
    "\n",
    "        # Sample hidden units for vk\n",
    "        phk, _ = rbm.sample_h(vk)  # phk shape: (batch_size, n_hidden)\n",
    "\n",
    "        # Train the RBM\n",
    "        rbm.train(v0, vk, ph0, phk)\n",
    "\n",
    "        # Compute training loss (MAE for rated items)\n",
    "        train_loss += torch.mean(torch.abs(v0[v0 >= 0] - vk[v0 >= 0]))\n",
    "        s += 1.0\n",
    "\n",
    "    # Print epoch loss\n",
    "    print(f\"epoch: {epoch}, loss: {train_loss / s}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.005148433614522219\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "s = 0.0\n",
    "for id_user in range(0, nb_users):\n",
    "    # Get a batch of visible units\n",
    "    v = training_set[id_user:id_user+1]\n",
    "    vt = test_set[id_user:id_user+1]\n",
    "    \n",
    "    # Perform CD-k (random walk)\n",
    "    if len(vt[vt>=0]) > 0:\n",
    "        _, h = rbm.sample_h(v)\n",
    "        _, v = rbm.sample_v(h)\n",
    "\n",
    "        test_loss += torch.mean(torch.abs(vt[vt >= 0] - v[vt >= 0]))\n",
    "        s += 1.0\n",
    "\n",
    "# Print loss\n",
    "print(f\"test loss: {train_loss / s}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
